{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import apex\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from det3d import __version__, torchie\n",
    "from det3d.datasets import build_dataloader, build_dataset\n",
    "from det3d.datasets.kitti import kitti_common as kitti\n",
    "from det3d.models import build_detector\n",
    "from det3d.torchie import Config\n",
    "from det3d.torchie.apis import (\n",
    "    batch_processor,\n",
    "    build_optimizer,\n",
    "    get_root_logger,\n",
    "    init_dist,\n",
    "    set_random_seed,\n",
    "    train_detector,\n",
    ")\n",
    "from det3d.torchie.trainer import get_dist_info, load_checkpoint\n",
    "from det3d.torchie.trainer.utils import all_gather, synchronize\n",
    "from torch.nn.parallel import DistributedDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Train a detector\")\n",
    "    parser.add_argument(\"config\", help=\"train config file path\")\n",
    "    parser.add_argument(\"--work_dir\", help=\"the dir to save logs and models\")\n",
    "    parser.add_argument(\n",
    "        \"--checkpoint\", help=\"the dir to checkpoint which the model read from\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--txt_result\",\n",
    "        type=bool,\n",
    "        default=False,\n",
    "        help=\"whether to save results to standard KITTI format of txt type\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gpus\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"number of gpus to use \" \"(only applicable to non-distributed training)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--launcher\",\n",
    "        choices=[\"none\", \"pytorch\", \"slurm\", \"mpi\"],\n",
    "        default=\"none\",\n",
    "        help=\"job launcher\",\n",
    "    )\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "\n",
    "    #args = parser.parse_args() #elodie\n",
    "\n",
    "    #args = parser.parse_args('examples/second/configs/kitti_all_vfev3_spmiddlefhd_rpn1_mghead_syncbn.py --work_dir /home/elodie/det3D_Output/Outputs/Det3D_Outputs/SECOND_all_3_20200220-101802 --checkpoint /home/elodie/det3D_Output/Outputs/Det3D_Outputs/SECOND_all_3_20200220-101802/latest.pth --txt_result True'.split())\n",
    "    args = parser.parse_args('examples/second/configs/kitti_all_vfev3_spmiddlefhd_rpn1_mghead_syncbn_freatures3.py --work_dir /home/elodie/model_pth/SECOND_F3_all_1_20200305-093312 --checkpoint /home/elodie/model_pth/SECOND_F3_all_1_20200305-093312/latest.pth --txt_result True'.split())\n",
    "\n",
    "    if \"LOCAL_RANK\" not in os.environ:\n",
    "        os.environ[\"LOCAL_RANK\"] = str(args.local_rank)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "args = parse_args()\n",
    "cfg = Config.fromfile(args.config)\n",
    "cfg.local_rank = args.local_rank\n",
    "# update configs according to CLI args\n",
    "if args.work_dir is not None:\n",
    "    cfg.work_dir = args.work_dir\n",
    "#print(\"Config:\\n cfg.local_rank:\",cfg.local_rank,\"\\ncfg.data.val:\",cfg.data.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed: False\n",
      "cfg.gpus: 1\n"
     ]
    }
   ],
   "source": [
    "distributed = False\n",
    "if \"WORLD_SIZE\" in os.environ:\n",
    "    distributed = int(os.environ[\"WORLD_SIZE\"]) > 1\n",
    "print(\"distributed:\",distributed)\n",
    "if distributed:\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "\n",
    "    cfg.gpus = torch.distributed.get_world_size()\n",
    "else:\n",
    "    cfg.gpus = args.gpus\n",
    "print(\"cfg.gpus:\",cfg.gpus)\n",
    "logger = get_root_logger(cfg.log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_loader: <torch.utils.data.dataloader.DataLoader object at 0x7f5d8c364390>\n"
     ]
    }
   ],
   "source": [
    "dataset = build_dataset(cfg.data.val)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    batch_size=cfg.data.samples_per_gpu,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=distributed,\n",
    "    shuffle=False,\n",
    ")\n",
    "print(\"data_loader:\",data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-28 18:09:25,895 - INFO - Finish RPN Initialization\n",
      "2020-03-28 18:09:25,896 - INFO - num_classes: [1, 1, 1], num_preds: [14, 14, 14], num_dirs: [4, 4, 4]\n",
      "2020-03-28 18:09:25,898 - INFO - Finish MultiGroupHead Initialization\n"
     ]
    }
   ],
   "source": [
    "model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = load_checkpoint(model, args.checkpoint, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()#cuda()函数都能实现从CPU到GPU的内存迁移,对model自身进行的内存迁移。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VoxelNet(\n",
       "  (reader): VoxelFeatureExtractorV3()\n",
       "  (backbone): SpMiddleFHD(\n",
       "    (middle_conv): SparseSequential(\n",
       "      (0): SubMConv3d()\n",
       "      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): SubMConv3d()\n",
       "      (4): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): SparseConv3d()\n",
       "      (7): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (8): ReLU()\n",
       "      (9): SubMConv3d()\n",
       "      (10): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (11): ReLU()\n",
       "      (12): SubMConv3d()\n",
       "      (13): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (14): ReLU()\n",
       "      (15): SparseConv3d()\n",
       "      (16): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (17): ReLU()\n",
       "      (18): SubMConv3d()\n",
       "      (19): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (20): ReLU()\n",
       "      (21): SubMConv3d()\n",
       "      (22): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (23): ReLU()\n",
       "      (24): SubMConv3d()\n",
       "      (25): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (26): ReLU()\n",
       "      (27): SparseConv3d()\n",
       "      (28): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (29): ReLU()\n",
       "      (30): SubMConv3d()\n",
       "      (31): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (32): ReLU()\n",
       "      (33): SubMConv3d()\n",
       "      (34): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (35): ReLU()\n",
       "      (36): SubMConv3d()\n",
       "      (37): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (38): ReLU()\n",
       "      (39): SparseConv3d()\n",
       "      (40): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (41): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (neck): RPN(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (9): ReLU()\n",
       "        (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (12): ReLU()\n",
       "        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (15): ReLU()\n",
       "        (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (18): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (deblocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bbox_head): MultiGroupHead(\n",
       "    (loss_cls): SigmoidFocalLoss()\n",
       "    (loss_reg): WeightedSmoothL1Loss()\n",
       "    (loss_aux): WeightedSoftmaxClassificationLoss()\n",
       "    (tasks): ModuleList(\n",
       "      (0): Head(\n",
       "        (conv_box): Conv2d(128, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv_cls): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv_dir): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Head(\n",
       "        (conv_box): Conv2d(128, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv_cls): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv_dir): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Head(\n",
       "        (conv_box): Conv2d(128, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv_cls): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv_dir): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[                              ] 0/3769, elapsed: 0s, ETA:"
     ]
    }
   ],
   "source": [
    "print(cfg.local_rank)\n",
    "prog_bar = torchie.ProgressBar(len(data_loader.dataset) // cfg.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = {}\n",
    "cpu_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.no_grad()\n",
      "[                              ] 6/3769, 1.7 task/s, elapsed: 3s, ETA:  2162storch.no_grad()\n",
      "[                              ] 12/3769, 3.2 task/s, elapsed: 4s, ETA:  1184storch.no_grad()\n",
      "[                              ] 18/3769, 4.5 task/s, elapsed: 4s, ETA:   842storch.no_grad()\n",
      "[                              ] 24/3769, 5.6 task/s, elapsed: 4s, ETA:   664storch.no_grad()\n",
      "[                              ] 30/3769, 6.6 task/s, elapsed: 5s, ETA:   563storch.no_grad()\n",
      "[                              ] 36/3769, 7.6 task/s, elapsed: 5s, ETA:   493storch.no_grad()\n",
      "[                              ] 42/3769, 8.5 task/s, elapsed: 5s, ETA:   440storch.no_grad()\n",
      "[                              ] 48/3769, 9.1 task/s, elapsed: 5s, ETA:   407storch.no_grad()\n",
      "[                              ] 54/3769, 9.8 task/s, elapsed: 5s, ETA:   378storch.no_grad()\n",
      "[                              ] 60/3769, 10.5 task/s, elapsed: 6s, ETA:   353storch.no_grad()\n",
      "[                              ] 66/3769, 11.1 task/s, elapsed: 6s, ETA:   334storch.no_grad()\n",
      "[                              ] 72/3769, 11.6 task/s, elapsed: 6s, ETA:   319storch.no_grad()\n",
      "[                              ] 78/3769, 12.1 task/s, elapsed: 6s, ETA:   305storch.no_grad()\n",
      "[                              ] 84/3769, 11.9 task/s, elapsed: 7s, ETA:   309storch.no_grad()\n",
      "[                              ] 90/3769, 12.4 task/s, elapsed: 7s, ETA:   297storch.no_grad()\n",
      "[                              ] 96/3769, 12.8 task/s, elapsed: 7s, ETA:   287storch.no_grad()\n",
      "[                              ] 102/3769, 13.2 task/s, elapsed: 8s, ETA:   277storch.no_grad()\n",
      "[                              ] 108/3769, 13.6 task/s, elapsed: 8s, ETA:   269storch.no_grad()\n",
      "[                              ] 114/3769, 13.9 task/s, elapsed: 8s, ETA:   263storch.no_grad()\n",
      "[                              ] 120/3769, 13.8 task/s, elapsed: 9s, ETA:   264storch.no_grad()\n",
      "[>                             ] 126/3769, 14.1 task/s, elapsed: 9s, ETA:   258storch.no_grad()\n",
      "[>                             ] 132/3769, 14.4 task/s, elapsed: 9s, ETA:   252storch.no_grad()\n",
      "[>                             ] 138/3769, 14.7 task/s, elapsed: 9s, ETA:   248storch.no_grad()\n",
      "[>                             ] 144/3769, 14.9 task/s, elapsed: 10s, ETA:   243storch.no_grad()\n",
      "[>                             ] 150/3769, 15.2 task/s, elapsed: 10s, ETA:   239storch.no_grad()\n",
      "[>                             ] 156/3769, 14.8 task/s, elapsed: 11s, ETA:   245storch.no_grad()\n",
      "[>                             ] 162/3769, 15.0 task/s, elapsed: 11s, ETA:   240storch.no_grad()\n",
      "[>                             ] 168/3769, 15.3 task/s, elapsed: 11s, ETA:   236storch.no_grad()\n",
      "[>                             ] 174/3769, 15.5 task/s, elapsed: 11s, ETA:   232storch.no_grad()\n",
      "[>                             ] 180/3769, 15.7 task/s, elapsed: 11s, ETA:   229storch.no_grad()\n",
      "[>                             ] 186/3769, 15.9 task/s, elapsed: 12s, ETA:   225storch.no_grad()\n",
      "[>                             ] 192/3769, 15.5 task/s, elapsed: 12s, ETA:   230storch.no_grad()\n",
      "[>                             ] 198/3769, 15.7 task/s, elapsed: 13s, ETA:   227storch.no_grad()\n",
      "[>                             ] 204/3769, 15.9 task/s, elapsed: 13s, ETA:   224storch.no_grad()\n",
      "[>                             ] 210/3769, 16.1 task/s, elapsed: 13s, ETA:   221storch.no_grad()\n",
      "[>                             ] 216/3769, 16.3 task/s, elapsed: 13s, ETA:   219storch.no_grad()\n",
      "[>                             ] 222/3769, 16.4 task/s, elapsed: 14s, ETA:   216storch.no_grad()\n",
      "[>                             ] 228/3769, 16.1 task/s, elapsed: 14s, ETA:   220storch.no_grad()\n",
      "[>                             ] 234/3769, 16.2 task/s, elapsed: 14s, ETA:   218storch.no_grad()\n",
      "[>                             ] 240/3769, 16.4 task/s, elapsed: 15s, ETA:   215storch.no_grad()\n",
      "[>                             ] 246/3769, 16.5 task/s, elapsed: 15s, ETA:   213storch.no_grad()\n",
      "[>>                            ] 252/3769, 16.7 task/s, elapsed: 15s, ETA:   211storch.no_grad()\n",
      "[>>                            ] 258/3769, 16.9 task/s, elapsed: 15s, ETA:   208storch.no_grad()\n",
      "[>>                            ] 264/3769, 16.6 task/s, elapsed: 16s, ETA:   211storch.no_grad()\n",
      "[>>                            ] 270/3769, 16.7 task/s, elapsed: 16s, ETA:   209storch.no_grad()\n",
      "[>>                            ] 276/3769, 16.9 task/s, elapsed: 16s, ETA:   207storch.no_grad()\n",
      "[>>                            ] 282/3769, 17.0 task/s, elapsed: 17s, ETA:   205storch.no_grad()\n",
      "[>>                            ] 288/3769, 17.2 task/s, elapsed: 17s, ETA:   203storch.no_grad()\n",
      "[>>                            ] 294/3769, 17.1 task/s, elapsed: 17s, ETA:   203storch.no_grad()\n",
      "[>>                            ] 300/3769, 17.0 task/s, elapsed: 18s, ETA:   204storch.no_grad()\n",
      "[>>                            ] 306/3769, 17.1 task/s, elapsed: 18s, ETA:   203storch.no_grad()\n",
      "[>>                            ] 312/3769, 17.2 task/s, elapsed: 18s, ETA:   201storch.no_grad()\n",
      "[>>                            ] 318/3769, 17.3 task/s, elapsed: 18s, ETA:   200storch.no_grad()\n",
      "[>>                            ] 324/3769, 17.4 task/s, elapsed: 19s, ETA:   198storch.no_grad()\n",
      "[>>                            ] 330/3769, 17.4 task/s, elapsed: 19s, ETA:   198storch.no_grad()\n",
      "[>>                            ] 336/3769, 17.3 task/s, elapsed: 19s, ETA:   199storch.no_grad()\n",
      "[>>                            ] 342/3769, 17.3 task/s, elapsed: 20s, ETA:   198storch.no_grad()\n",
      "[>>                            ] 348/3769, 17.4 task/s, elapsed: 20s, ETA:   196storch.no_grad()\n",
      "[>>                            ] 354/3769, 17.5 task/s, elapsed: 20s, ETA:   195storch.no_grad()\n",
      "[>>                            ] 360/3769, 17.6 task/s, elapsed: 20s, ETA:   193storch.no_grad()\n",
      "[>>                            ] 366/3769, 17.7 task/s, elapsed: 21s, ETA:   193storch.no_grad()\n",
      "[>>                            ] 372/3769, 17.5 task/s, elapsed: 21s, ETA:   194storch.no_grad()\n",
      "[>>>                           ] 378/3769, 17.6 task/s, elapsed: 21s, ETA:   193storch.no_grad()\n",
      "[>>>                           ] 384/3769, 17.7 task/s, elapsed: 22s, ETA:   191storch.no_grad()\n",
      "[>>>                           ] 390/3769, 17.8 task/s, elapsed: 22s, ETA:   190storch.no_grad()\n",
      "[>>>                           ] 396/3769, 17.8 task/s, elapsed: 22s, ETA:   189storch.no_grad()\n",
      "[>>>                           ] 402/3769, 17.8 task/s, elapsed: 23s, ETA:   190storch.no_grad()\n",
      "[>>>                           ] 408/3769, 17.7 task/s, elapsed: 23s, ETA:   190storch.no_grad()\n",
      "[>>>                           ] 414/3769, 17.7 task/s, elapsed: 23s, ETA:   189storch.no_grad()\n",
      "[>>>                           ] 420/3769, 17.8 task/s, elapsed: 24s, ETA:   188storch.no_grad()\n",
      "[>>>                           ] 426/3769, 17.9 task/s, elapsed: 24s, ETA:   187storch.no_grad()\n",
      "[>>>                           ] 432/3769, 18.0 task/s, elapsed: 24s, ETA:   185storch.no_grad()\n",
      "[>>>                           ] 438/3769, 17.9 task/s, elapsed: 24s, ETA:   186storch.no_grad()\n",
      "[>>>                           ] 444/3769, 17.9 task/s, elapsed: 25s, ETA:   186storch.no_grad()\n",
      "[>>>                           ] 450/3769, 18.0 task/s, elapsed: 25s, ETA:   185storch.no_grad()\n",
      "[>>>                           ] 456/3769, 18.0 task/s, elapsed: 25s, ETA:   184storch.no_grad()\n",
      "[>>>                           ] 462/3769, 18.1 task/s, elapsed: 25s, ETA:   183storch.no_grad()\n",
      "[>>>                           ] 468/3769, 18.2 task/s, elapsed: 26s, ETA:   181storch.no_grad()\n",
      "[>>>                           ] 474/3769, 18.1 task/s, elapsed: 26s, ETA:   182storch.no_grad()\n",
      "[>>>                           ] 480/3769, 18.1 task/s, elapsed: 27s, ETA:   182storch.no_grad()\n",
      "[>>>                           ] 486/3769, 18.1 task/s, elapsed: 27s, ETA:   181storch.no_grad()\n",
      "[>>>                           ] 492/3769, 18.2 task/s, elapsed: 27s, ETA:   180storch.no_grad()\n",
      "[>>>                           ] 498/3769, 18.3 task/s, elapsed: 27s, ETA:   179storch.no_grad()\n",
      "[>>>>                          ] 504/3769, 18.3 task/s, elapsed: 28s, ETA:   179storch.no_grad()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>                          ] 510/3769, 18.2 task/s, elapsed: 28s, ETA:   179storch.no_grad()\n",
      "[>>>>                          ] 516/3769, 18.2 task/s, elapsed: 28s, ETA:   179storch.no_grad()\n",
      "[>>>>                          ] 522/3769, 18.2 task/s, elapsed: 29s, ETA:   178storch.no_grad()\n",
      "[>>>>                          ] 528/3769, 18.3 task/s, elapsed: 29s, ETA:   177storch.no_grad()\n",
      "[>>>>                          ] 534/3769, 18.4 task/s, elapsed: 29s, ETA:   176storch.no_grad()\n",
      "[>>>>                          ] 540/3769, 18.4 task/s, elapsed: 29s, ETA:   176storch.no_grad()\n",
      "[>>>>                          ] 546/3769, 18.3 task/s, elapsed: 30s, ETA:   176storch.no_grad()\n",
      "[>>>>                          ] 552/3769, 18.3 task/s, elapsed: 30s, ETA:   176storch.no_grad()\n",
      "[>>>>                          ] 558/3769, 18.4 task/s, elapsed: 30s, ETA:   175storch.no_grad()\n",
      "[>>>>                          ] 564/3769, 18.4 task/s, elapsed: 31s, ETA:   174storch.no_grad()\n",
      "[>>>>                          ] 570/3769, 18.5 task/s, elapsed: 31s, ETA:   173storch.no_grad()\n",
      "[>>>>                          ] 576/3769, 18.5 task/s, elapsed: 31s, ETA:   172storch.no_grad()\n",
      "[>>>>                          ] 582/3769, 18.4 task/s, elapsed: 32s, ETA:   173storch.no_grad()\n",
      "[>>>>                          ] 588/3769, 18.4 task/s, elapsed: 32s, ETA:   173storch.no_grad()\n",
      "[>>>>                          ] 594/3769, 18.5 task/s, elapsed: 32s, ETA:   172storch.no_grad()\n",
      "[>>>>                          ] 600/3769, 18.5 task/s, elapsed: 32s, ETA:   171storch.no_grad()\n",
      "[>>>>                          ] 606/3769, 18.6 task/s, elapsed: 33s, ETA:   170storch.no_grad()\n",
      "[>>>>                          ] 612/3769, 18.6 task/s, elapsed: 33s, ETA:   170storch.no_grad()\n",
      "[>>>>                          ] 618/3769, 18.5 task/s, elapsed: 33s, ETA:   170storch.no_grad()\n",
      "[>>>>                          ] 624/3769, 18.6 task/s, elapsed: 34s, ETA:   169storch.no_grad()\n",
      "[>>>>>                         ] 630/3769, 18.6 task/s, elapsed: 34s, ETA:   169storch.no_grad()\n",
      "[>>>>>                         ] 636/3769, 18.7 task/s, elapsed: 34s, ETA:   168storch.no_grad()\n",
      "[>>>>>                         ] 642/3769, 18.7 task/s, elapsed: 34s, ETA:   167storch.no_grad()\n",
      "[>>>>>                         ] 648/3769, 18.7 task/s, elapsed: 35s, ETA:   167storch.no_grad()\n",
      "[>>>>>                         ] 654/3769, 18.5 task/s, elapsed: 35s, ETA:   168storch.no_grad()\n",
      "[>>>>>                         ] 660/3769, 18.6 task/s, elapsed: 36s, ETA:   167storch.no_grad()\n",
      "[>>>>>                         ] 666/3769, 18.6 task/s, elapsed: 36s, ETA:   167storch.no_grad()\n",
      "[>>>>>                         ] 672/3769, 18.7 task/s, elapsed: 36s, ETA:   166storch.no_grad()\n",
      "[>>>>>                         ] 678/3769, 18.7 task/s, elapsed: 36s, ETA:   165storch.no_grad()\n",
      "[>>>>>                         ] 684/3769, 18.8 task/s, elapsed: 36s, ETA:   164storch.no_grad()\n",
      "[>>>>>                         ] 690/3769, 18.6 task/s, elapsed: 37s, ETA:   166storch.no_grad()\n",
      "[>>>>>                         ] 696/3769, 18.6 task/s, elapsed: 37s, ETA:   165storch.no_grad()\n",
      "[>>>>>                         ] 702/3769, 18.7 task/s, elapsed: 38s, ETA:   164storch.no_grad()\n",
      "[>>>>>                         ] 708/3769, 18.7 task/s, elapsed: 38s, ETA:   163storch.no_grad()\n",
      "[>>>>>                         ] 714/3769, 18.8 task/s, elapsed: 38s, ETA:   163storch.no_grad()\n",
      "[>>>>>                         ] 720/3769, 18.8 task/s, elapsed: 38s, ETA:   162storch.no_grad()\n",
      "[>>>>>                         ] 726/3769, 18.6 task/s, elapsed: 39s, ETA:   163storch.no_grad()\n",
      "[>>>>>                         ] 732/3769, 18.7 task/s, elapsed: 39s, ETA:   163storch.no_grad()\n",
      "[>>>>>                         ] 738/3769, 18.7 task/s, elapsed: 39s, ETA:   162storch.no_grad()\n",
      "[>>>>>                         ] 744/3769, 18.8 task/s, elapsed: 40s, ETA:   161storch.no_grad()\n",
      "[>>>>>                         ] 750/3769, 18.8 task/s, elapsed: 40s, ETA:   161storch.no_grad()\n",
      "[>>>>>>                        ] 756/3769, 18.8 task/s, elapsed: 40s, ETA:   160storch.no_grad()\n",
      "[>>>>>>                        ] 762/3769, 18.7 task/s, elapsed: 41s, ETA:   161storch.no_grad()\n",
      "[>>>>>>                        ] 768/3769, 18.6 task/s, elapsed: 41s, ETA:   161storch.no_grad()\n",
      "[>>>>>>                        ] 774/3769, 18.7 task/s, elapsed: 41s, ETA:   160storch.no_grad()\n",
      "[>>>>>>                        ] 780/3769, 18.7 task/s, elapsed: 42s, ETA:   160storch.no_grad()\n",
      "[>>>>>>                        ] 786/3769, 18.8 task/s, elapsed: 42s, ETA:   159storch.no_grad()\n",
      "[>>>>>>                        ] 792/3769, 18.8 task/s, elapsed: 42s, ETA:   158storch.no_grad()\n",
      "[>>>>>>                        ] 798/3769, 18.8 task/s, elapsed: 42s, ETA:   158storch.no_grad()\n",
      "[>>>>>>                        ] 804/3769, 18.7 task/s, elapsed: 43s, ETA:   158storch.no_grad()\n",
      "[>>>>>>                        ] 810/3769, 18.8 task/s, elapsed: 43s, ETA:   158storch.no_grad()\n",
      "[>>>>>>                        ] 816/3769, 18.8 task/s, elapsed: 43s, ETA:   157storch.no_grad()\n",
      "[>>>>>>                        ] 822/3769, 18.9 task/s, elapsed: 44s, ETA:   156storch.no_grad()\n",
      "[>>>>>>                        ] 828/3769, 18.9 task/s, elapsed: 44s, ETA:   156storch.no_grad()\n",
      "[>>>>>>                        ] 834/3769, 18.8 task/s, elapsed: 44s, ETA:   156storch.no_grad()\n",
      "[>>>>>>                        ] 840/3769, 18.8 task/s, elapsed: 45s, ETA:   156storch.no_grad()\n",
      "[>>>>>>                        ] 846/3769, 18.8 task/s, elapsed: 45s, ETA:   155storch.no_grad()\n",
      "[>>>>>>                        ] 852/3769, 18.9 task/s, elapsed: 45s, ETA:   155storch.no_grad()\n",
      "[>>>>>>                        ] 858/3769, 18.9 task/s, elapsed: 45s, ETA:   154storch.no_grad()\n",
      "[>>>>>>                        ] 864/3769, 18.9 task/s, elapsed: 46s, ETA:   153storch.no_grad()\n",
      "[>>>>>>                        ] 870/3769, 18.9 task/s, elapsed: 46s, ETA:   154storch.no_grad()\n",
      "[>>>>>>                        ] 876/3769, 18.8 task/s, elapsed: 47s, ETA:   154storch.no_grad()\n",
      "[>>>>>>>                       ] 882/3769, 18.9 task/s, elapsed: 47s, ETA:   153storch.no_grad()\n",
      "[>>>>>>>                       ] 888/3769, 18.9 task/s, elapsed: 47s, ETA:   152storch.no_grad()\n",
      "[>>>>>>>                       ] 894/3769, 18.9 task/s, elapsed: 47s, ETA:   152storch.no_grad()\n",
      "[>>>>>>>                       ] 900/3769, 19.0 task/s, elapsed: 47s, ETA:   151storch.no_grad()\n",
      "[>>>>>>>                       ] 906/3769, 18.9 task/s, elapsed: 48s, ETA:   151storch.no_grad()\n",
      "[>>>>>>>                       ] 912/3769, 18.9 task/s, elapsed: 48s, ETA:   151storch.no_grad()\n",
      "[>>>>>>>                       ] 918/3769, 18.9 task/s, elapsed: 49s, ETA:   151storch.no_grad()\n",
      "[>>>>>>>                       ] 924/3769, 18.9 task/s, elapsed: 49s, ETA:   150storch.no_grad()\n",
      "[>>>>>>>                       ] 930/3769, 19.0 task/s, elapsed: 49s, ETA:   150storch.no_grad()\n",
      "[>>>>>>>                       ] 936/3769, 19.0 task/s, elapsed: 49s, ETA:   149storch.no_grad()\n",
      "[>>>>>>>                       ] 942/3769, 19.0 task/s, elapsed: 50s, ETA:   149storch.no_grad()\n",
      "[>>>>>>>                       ] 948/3769, 19.0 task/s, elapsed: 50s, ETA:   149storch.no_grad()\n",
      "[>>>>>>>                       ] 954/3769, 19.0 task/s, elapsed: 50s, ETA:   148storch.no_grad()\n",
      "[>>>>>>>                       ] 960/3769, 19.0 task/s, elapsed: 50s, ETA:   148storch.no_grad()\n",
      "[>>>>>>>                       ] 966/3769, 19.0 task/s, elapsed: 51s, ETA:   147storch.no_grad()\n",
      "[>>>>>>>                       ] 972/3769, 19.1 task/s, elapsed: 51s, ETA:   147storch.no_grad()\n",
      "[>>>>>>>                       ] 978/3769, 19.0 task/s, elapsed: 52s, ETA:   147storch.no_grad()\n",
      "[>>>>>>>                       ] 984/3769, 19.0 task/s, elapsed: 52s, ETA:   147storch.no_grad()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1f59b5a1488d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#         print(data_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         outputs = batch_processor(\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_rank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         )\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         print(outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elodie/Det3D/det3d/torchie/apis/train.py\u001b[0m in \u001b[0;36mbatch_processor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/elodie/Det3D/det3d/models/detectors/voxelnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, example, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/elodie/Det3D/det3d/models/bbox_heads/mg_head.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, example, preds_dicts, test_cfg, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m                     \u001b[0mbatch_dir_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                     \u001b[0mbatch_anchors_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                     \u001b[0mmeta_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 )\n\u001b[1;32m    781\u001b[0m             )\n",
      "\u001b[0;32m/home/elodie/Det3D/det3d/models/bbox_heads/mg_head.py\u001b[0m in \u001b[0;36mget_task_detections\u001b[0;34m(self, task_id, num_class_with_bg, test_cfg, batch_cls_preds, batch_reg_preds, batch_dir_preds, batch_anchors_mask, meta_list)\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mpost_center_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_reg_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_reg_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m             )\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# aa = 0\n",
    "for i, data_batch in enumerate(data_loader):\n",
    "#     aa = aa+1\n",
    "#     if aa == 2:\n",
    "#         break\n",
    "    with torch.no_grad():  #torch.no_grad()禁用对autograd中的梯度的跟踪\n",
    "        print(\"torch.no_grad()\")\n",
    "#         print(data_batch)\n",
    "        outputs = batch_processor(\n",
    "            model, data_batch, train_mode=False, local_rank=args.local_rank,\n",
    "        )\n",
    "#         print(outputs)\n",
    "    for output in outputs:\n",
    "        token = output[\"metadata\"][\"token\"]\n",
    "        for k, v in output.items():\n",
    "            if k not in [\n",
    "                \"metadata\",\n",
    "            ]:\n",
    "                output[k] = v.to(cpu_device)\n",
    "        detections.update(\n",
    "            {token: output,}\n",
    "        )\n",
    "        if args.local_rank == 0:\n",
    "            prog_bar.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(detections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synchronize()\n",
    "all_predictions = all_gather(detections)\n",
    "predictions = {}\n",
    "for p in all_predictions:\n",
    "    predictions.update(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict, dt_annos = dataset.evaluation(predictions, output_dir=args.work_dir)\n",
    "\n",
    "# result_dict, detections = test(\n",
    "#    data_loader, model, save_dir=None, distributed=distributed\n",
    "#    )\n",
    "print(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_annos[3701])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.txt_result:\n",
    "    res_dir = \"/home/elodie/DockerDet3D/predictions_xyz_0\"\n",
    "    # for k, dt in predictions.items():\n",
    "    #for k, dt in dt_annos.items(): #elodie\n",
    "    for i in range(len(dt_annos)): #elodie\n",
    "        dt = dt_annos[i]\n",
    "        with open(\n",
    "            os.path.join(res_dir, \"%06d.txt\" % int(dt[\"metadata\"][\"token\"])), \"w\"\n",
    "        ) as fout:\n",
    "            print(dt)\n",
    "            lines = kitti.annos_to_kitti_label(dt)\n",
    "            for line in lines:\n",
    "                fout.write(line + \"\\n\")\n",
    "\n",
    "#     ap_result_str, ap_dict = kitti_evaluate(\n",
    "#         \"/data/Datasets/KITTI/Kitti/object/training/label_2\",\n",
    "#         res_dir,\n",
    "#         label_split_file=\"/data/Datasets/KITTI/Kitti/ImageSets/val.txt\",\n",
    "#         current_class=0,\n",
    "#     )\n",
    "\n",
    "#     print(ap_result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
